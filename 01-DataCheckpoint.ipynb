{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rubric\n",
    "\n",
    "Instructions: DELETE this cell before you submit via a `git push` to your repo before deadline. This cell is for your reference only and is not needed in your report. \n",
    "\n",
    "Scoring: Out of 10 points\n",
    "\n",
    "- Each Developing  => -2 pts\n",
    "- Each Unsatisfactory/Missing => -4 pts\n",
    "  - until the score is \n",
    "\n",
    "If students address the detailed feedback in a future checkpoint they will earn these points back\n",
    "\n",
    "\n",
    "|                  | Unsatisfactory                                                                                                                                                                                                    | Developing                                                                                                                                                                                              | Proficient                                     | Excellent                                                                                                                              |\n",
    "|------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Data relevance   | Did not have data relevant to their question. Or the datasets don't work together because there is no way to line them up against each other. If there are multiple datasets, most of them have this trouble | Data was only tangentially relevant to the question or a bad proxy for the question. If there are multiple datasets, some of them may be irrelevant or can't be easily combined.                       | All data sources are relevant to the question. | Multiple data sources for each aspect of the project. It's clear how the data supports the needs of the project.                         |\n",
    "| Data description | Dataset or its cleaning procedures are not described. If there are multiple datasets, most have this trouble                                                                                              | Data was not fully described. If there are multiple datasets, some of them are not fully described                                                                                                      | Data was fully described                       | The details of the data descriptions and perhaps some very basic EDA also make it clear how the data supports the needs of the project. |\n",
    "| Data wrangling   | Did not obtain data. They did not clean/tidy the data they obtained.  If there are multiple datasets, most have this trouble                                                                                 | Data was partially cleaned or tidied. Perhaps you struggled to verify that the data was clean because they did not present it well. If there are multiple datasets, some have this trouble | The data is cleaned and tidied.                | The data is spotless and they used tools to visualize the data cleanliness and you were convinced at first glance                      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "\n",
    "This is a modified [CRediT taxonomy of contributions](https://credit.niso.org). For each group member please list how they contributed to this project using these terms:\n",
    "> Analysis, Background research, Conceptualization, Data curation, Experimental investigation, Methodology, Project administration, Software, Visualization, Writing – original draft, Writing – review & editing\n",
    "\n",
    "Example team list and credits:\n",
    "- Assilem Martinez: Data curation, Visualization, Experimental investigation.\n",
    "- Mia Yanez: Writing, Background research, Analysis\n",
    "- Brandon Khuu: Project administration, Software, Writing, Data curation \n",
    "- Ivy Tucker: Experimental investigation, Analysis, Background research, Writing\n",
    "- Karina Goyal: Visualization, Background research, Writing - review and editing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions: REPLACE the contents of this cell with your work, including any updates to recover points lost in your proposal feedback\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions: REPLACE the contents of this cell with your work, including any updates to recover points lost in your proposal feedback"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions: REPLACE the contents of this cell with your work, including any updates to recover points lost in your proposal feedback\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data overview\n",
    "\n",
    "Instructions: REPLACE the contents of this cell with descriptions of your actual datasets.\n",
    "\n",
    "For each dataset include the following information\n",
    "- Dataset #1\n",
    "  - Dataset Name: U.S. Monthly Gasoline Prices\n",
    "  - Link to the dataset: https://www.eia.gov/dnav/pet/pet_pri_gnd_dcus_sca_w.htm\n",
    "  - Number of observations:\n",
    "  - Number of variables: 2\n",
    "  - Descripition of the variables:\n",
    "      - Date/Week Ending Date: Indicates when the price data were collected. This time index allows for trend analysis and linking to corresponding transit ridership data over the same periods.\n",
    "      - Price (Dollars per Gallon): Reflects the average retail price consumers pay at gas stations for all grades and formulations of gasoline (including taxes). This is the main independent variable used in the project because changes in gasoline prices can influence individual travel behavior and transit ridership patterns.\n",
    "\n",
    "  - Descriptions of any shortcomings:\n",
    "      - Regional Aggregation: The price data represent a statewide average for California rather than localized values for specific metropolitan areas. Gasoline prices can vary significantly by city or region due to taxes, regulations, and supply differences, so the statewide average may not capture local price signals that influence ridership.\n",
    "      - Frequency and Timing: The original data are reported weekly, and converting to monthly averages may obscure short-term spikes or declines that could correlate with weekly ridership changes.\n",
    "\n",
    "- Dataset #2\n",
    "  - Dataset Name: Monthly Public Transit Ridership\n",
    "  - Link to the dataset: https://www.transit.dot.gov/ntd/data-product/monthly-module-adjusted-data-release\n",
    "  - Number of observations:\n",
    "  - Number of variables\n",
    "  - Description of te varaiables most relevant to this project\n",
    "  - Descriptions of any shortcomings this dataset has with repsect to the project\n",
    "\n",
    "Each dataset deserves either a set of bullet points as above or a few sentences if you prefer that method.\n",
    "\n",
    "If you plan to use multiple datasets, add a few sentences about how you plan to combine these datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Run this code every time when you're actively developing modules in .py files.  It's not needed if you aren't making modules\n",
    "#\n",
    "## this code is necessary for making sure that any modules we load are updated here \n",
    "## when their source code .py files are modified\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Download Progress:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Downloading airline-safety.csv:   0%|          | 0.00/1.23k [00:00<?, ?B/s]\u001b[A\n",
      "                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: airline-safety.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading bad-drivers.csv:   0%|          | 0.00/1.37k [00:00<?, ?B/s]\u001b[A\n",
      "Overall Download Progress: 100%|██████████| 2/2 [00:00<00:00, 15.10it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: bad-drivers.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Setup code -- this only needs to be run once after cloning the repo!\n",
    "# this code downloads the data from its source to the `data/00-raw/` directory\n",
    "# if the data hasn't updated you don't need to do this again!\n",
    "\n",
    "# if you don't already have these packages (you should!) uncomment this line\n",
    "# %pip install requests tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('./modules') # this tells python where to look for modules to import\n",
    "\n",
    "import get_data # this is where we get the function we need to download data\n",
    "\n",
    "# replace the urls and filenames in this list with your actual datafiles\n",
    "# yes you can use Google drive share links or whatever\n",
    "# format is a list of dictionaries; \n",
    "# each dict has keys of \n",
    "#   'url' where the resource is located\n",
    "#   'filename' for the local filename where it will be stored \n",
    "datafiles = [\n",
    "    { 'url': 'https://raw.githubusercontent.com/fivethirtyeight/data/refs/heads/master/airline-safety/airline-safety.csv', 'filename':'airline-safety.csv'},\n",
    "    { 'url': 'https://raw.githubusercontent.com/fivethirtyeight/data/refs/heads/master/bad-drivers/bad-drivers.csv', 'filename':'bad-drivers.csv'}\n",
    "]\n",
    "\n",
    "get_data.get_raw(datafiles,destination_directory='data/00-raw/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #1: California Weekly Retail Gasoline Prices (All Grades, All Formulations)\n",
    "This dataset contains weekly average retail gasoline prices in California, measured in dollars per gallon. The data is published by the U.S. Energy Information Administration, a federal agency that collects and standardizes energy statistics across the country. The reported values represent the average price consumers pay at gas stations throughout California for all grades and all formulations of gasoline, including applicable taxes.\n",
    "\n",
    "The primary metric in this dataset is retail gasoline price, expressed in dollars per gallon. For example, a value of 2.50 indicates that gasoline costs \\$2.50 per gallon during that week. Historically, prices in this dataset range from approximately \\$1.12 per gallon at the lowest to over \\$6.00 per gallon at the highest. Lower values generally reflect periods of reduced oil demand, economic downturns, or temporary supply surpluses. Higher values typically occur during supply disruptions, refinery constraints, inflationary pressures, or geopolitical conflicts that affect crude oil markets. Since gasoline is a major transportation expense for households, changes in price can significantly influence driving behavior. When gasoline prices increase substantially, individuals may reduce discretionary driving, carpool, or consider alternatives such as public transit. Therefore, gasoline price serves as a relevant independent variable for analyzing changes in public transit ridership over time.\n",
    "\n",
    "#### Major Concerns and Limitations\n",
    "\n",
    "One concern with this dataset is that it reflects an average price across the entire state of California. Gasoline prices can vary widely between regions within the state due to local taxes, environmental regulations, and supply chain differences. As a result, the statewide average may not perfectly capture the price signals that influence transit ridership in specific metropolitan areas.\n",
    "\n",
    "Additionally, gasoline price is only one factor influencing public transit ridership. Transit usage is also affected by service frequency, route availability, population density, employment patterns, and weather conditions. Because these additional factors are not included in the dataset, gasoline price alone cannot fully explain changes in ridership.\n",
    "\n",
    "Overall, the dataset is reliable, standardized, and appropriate for analyzing fuel cost trends over time. However, its statewide aggregation and lack of contextual behavioral variables should be considered when interpreting results in relation to public transit usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Date  \\\n",
      "0  Jan 02, 1995   \n",
      "1  Jan 09, 1995   \n",
      "2  Jan 16, 1995   \n",
      "3  Jan 23, 1995   \n",
      "4  Jan 30, 1995   \n",
      "\n",
      "   Weekly California All Grades All Formulations Retail Gasoline Prices  (Dollars per Gallon)  \\\n",
      "0                                                NaN                                            \n",
      "1                                                NaN                                            \n",
      "2                                                NaN                                            \n",
      "3                                                NaN                                            \n",
      "4                                                NaN                                            \n",
      "\n",
      "   Unnamed: 2  Unnamed: 3  Unnamed: 4  Unnamed: 5  Unnamed: 6  \n",
      "0         NaN         NaN         NaN         NaN         NaN  \n",
      "1         NaN         NaN         NaN         NaN         NaN  \n",
      "2         NaN         NaN         NaN         NaN         NaN  \n",
      "3         NaN         NaN         NaN         NaN         NaN  \n",
      "4         NaN         NaN         NaN         NaN         NaN  \n",
      "Index(['Date',\n",
      "       'Weekly California All Grades All Formulations Retail Gasoline Prices  (Dollars per Gallon)',\n",
      "       'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#Read as CSV (comma-separated)\n",
    "gas_df = pd.read_csv('gas_prices.csv', header=0)\n",
    "\n",
    "# Check first few rows\n",
    "print(gas_df.head())\n",
    "print(gas_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Date  Gas_Price\n",
      "281 2000-05-22      1.679\n",
      "282 2000-05-29      1.673\n",
      "283 2000-06-05      1.661\n",
      "284 2000-06-12      1.662\n",
      "285 2000-06-19      1.664\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#reads the csv file into a dataframe within the imported pandas. Gets the raw data into a structured table in python.\n",
    "gas_df = pd.read_csv('gas_prices.csv')\n",
    "\n",
    "# renaming the column names for ease to work with and additionally provides a cleaner data set to work with\n",
    "gas_df.rename(columns={'Weekly California All Grades All Formulations Retail Gasoline Prices  (Dollars per Gallon)': 'Gas_Price'}, inplace=True)\n",
    "\n",
    "# Originally had to create a clean version of the data and this code allows \n",
    "gas_df = gas_df[['Date', 'Gas_Price']]\n",
    "\n",
    "# this code helps with sorting any time within the dataset like any dates accurately\n",
    "gas_df['Date'] = pd.to_datetime(gas_df['Date'], errors='coerce')\n",
    "\n",
    "# turns data into numeric values for actual calculations which is necessary for datasets\n",
    "gas_df['Gas_Price'] = pd.to_numeric(gas_df['Gas_Price'], errors='coerce')\n",
    "\n",
    "#any missing values can distort data and how its interpreted in later sections\n",
    "gas_df = gas_df.dropna(subset=['Gas_Price'])\n",
    "\n",
    "print(gas_df.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #2: December 2025 Complete Monthly Ridership (with Adjustments and Estimates)\n",
    "\n",
    "This dataset contains monthly public transit ridership and operational data for transit agencies across the United States. The data is reported to the Federal Transit Administration through the National Transit Database, which collects and standardizes transit performance statistics nationwide. \n",
    "\n",
    "The primary metric in this dataset is Unlinked Passenger Trips, which measures the number of individual boardings on public transit vehicles. Each boarding counts as one trip, even if a rider transfers between services. For example, if a commuter boards a bus and later transfers to a train, this counts as two unlinked passenger trips. Higher UPT values indicate greater transit usage, while lower values reflect reduced ridership. Ridership levels fluctuate in response to economic conditions, fuel prices, employment trends, seasonal patterns, and service availability.\n",
    "\n",
    "#### Major Concerns and Limitations\n",
    "\n",
    "One concern with this dataset is that it aggregates data at the agency and mode level. While this provides a comprehensive national overview, it does not capture variation within specific routes or subregions. Localized ridership changes may therefore be masked by totals.\n",
    "\n",
    "Overall, this dataset is reliable, standardized, and appropriate for analyzing public transit activity and operational performance. However, its aggregated structure and limited contextual variables should be considered when interpreting results in relation to broader transportation trends.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions: REPLACE the contents of this cell with your work, including any updates to recover points lost in your proposal feedback"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Expectations "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The expectation for communication is that all members respond to project related messages in our group chat within 12 hours, allowing for good progress and checkins\n",
    "* We will meet on Zoom or in person at least twice a week to stay on top our goals, deadlines, and responsibilities\n",
    "* We have agreed to actively share ideas while always leaving the floor open for thoughts, comments, and concerns, which we believe will create a collaborative environment.\n",
    "* When making decisions, all members will communicate how they feel and explain their reasoning. This allows us to identify different perspectives early, and make sure everyone is actually on the same page. Although each member will take on a specific role, roles remain flexible and open to revision so that everyone can contribute.\n",
    "* If any member is struggling to keep up, they have agreed to inform the group in good time. In response, the team will dedicate at least 30 minutes to provide support and adjust plans as needed.\n",
    "* If conflicts arise that cannot be resolved within, we believe it is best to ask help from a TA to help us move forward respectfully and collaboratively.\n",
    "* All members agree to come to meetings prepared, having completed assigned tasks or reviewed relevant materials in advance to make meeting times more helpful and respectful of others time.\n",
    "* The team agrees to regularly checking in to make sure that work is distributed fairly and adjusted if not.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Timeline Proposal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 1/29  |  5 PM | Look over the project proposal assignment; Prepare any questions about the assignment | Share our ideas for project/research questions and interest; Move things around on the repo and help if any confusions arise | \n",
    "| 2/01  |  3 PM |  Reflect on proposed deas and brainstorm how each can be worked on | Begin to draft the propject proposal and discuss group dynamic as stated on the proposal document; Talk about which ideas stick out more and can be interesting for this project| \n",
    "| 2/03  | 8:30 PM | Add the contributions to document discussed in previous meeting; Edit and alter our finalized idea to fit the guidelines of the proposal rubric; begin to look into what datasets would match our research question | Share what we find on datasets and begin to have practice with getting it onto a notebook (experimentally before we finalize any data sets |\n",
    "| 2/11  | 5 PM  | Each person looks at the datasets we have and be prepared to hsare with the group how we can use it in our research and what specific features would be unnecessary to keep (Ant Man);| Import & Wrangle Data as a group to be able to see what can be changed on the spot; giving feedback on code and learning from each other;Have at least two people share on the analysis portion to the data that was imported and wrangled and how it refelcts the research question |\n",
    "| 2/17  | 8:30 PM  |Continue to add to the code through individuals branch to help our visuals such as graphs and wrangling done) | Give time for questions and feedback; Make sure our varibales are making sense and contributing to the research question |\n",
    "| 2/23  | 3 PM  | Brush up any parts of the data checpoint that is still unclear;| Take the meeting time to discuss the direction of the project and take a overview of what future code can add/contribut and how that can change things|\n",
    "| 2/26  | 6 PM  | Work on assigned portions of details and analysis; Contrinute to final drafting work| Look at code together to make sure were getting what were intending to target and overall project progress |\n",
    "| 3/4  | 5 PM  | Review the feedback we recieved from the 1st checkpoint| Plan what we can fix if any points were deducted and take a look at checkpoint 2 |\n",
    "| 3/20  | Before 11:59 PM  | NA | Turn in Final Project & Group Project Surveys |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "16b860a9f5fc21240e9d88c0ee13691518c3ce67be252e54a03b9b5b11bd3c7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
